{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original codebase is thanks to Robbie Barrat who so graciously put his code on github at:\n",
    "https://github.com/robbiebarrat/rapping-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(lyrics):\n",
    "    lyrics = lyrics.replace(\"Chorus:\", \"\")\n",
    "    lyrics = lyrics.replace(\"[Chorus]\", \"\")\n",
    "    lyrics = lyrics.replace(\"Verse 1:\", \"\")\n",
    "    lyrics = lyrics.replace(\"Verse 2:\", \"\")\n",
    "    lyrics = lyrics.replace(\"Verse 3:\", \"\")\n",
    "    lyrics = lyrics.replace(\"Verse 1\", \"\")\n",
    "    lyrics = lyrics.replace(\"Verse 2\", \"\")\n",
    "    lyrics = lyrics.replace(\"Verse 3\", \"\")\n",
    "    lyrics = lyrics.replace(\"[Verse 1]\", \"\")\n",
    "    lyrics = lyrics.replace(\"[Verse 2]\", \"\")\n",
    "    lyrics = lyrics.replace(\"[Verse 3]\", \"\")\n",
    "    lyrics = lyrics.replace(\"(Verse 1)\", \"\")\n",
    "    lyrics = lyrics.replace(\"(Verse 2)\", \"\")\n",
    "    lyrics = lyrics.replace(\"(Chorus)\", \"\")\n",
    "    lyrics = lyrics.replace(\"Intro:\", \"\")\n",
    "    lyrics = lyrics.replace(\"Outro\", \"\")\n",
    "    lyrics = lyrics.replace(\"2nd verse:\", \"\")\n",
    "    lyrics = lyrics.replace(\"1st verse:\", \"\")\n",
    "    lyrics = lyrics.replace(\"[ chorus ]\", \"\")\n",
    "    lyrics = lyrics.replace(\"[]\", \"\")\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "LYRICS_DIR = '/Users/jacobwagner/Desktop/lyrics.csv'\n",
    "nameList = [\"ariana-grande\", \"beyonce-knowles\", 'adele', 'destiny-s-child', 'adam-rafferty',\n",
    "            'akon', 'the-chainsmokers', '5-seconds-of-summer', 'the-chipettes', 'bee-gees',\n",
    "           'alicia-keys', 'alessia-cara', 'billie', 'barbara-streisand', 'carly-rae-jepsen',\n",
    "           'beyonce', 'christina-aguilera', 'ashley-tisdale', 'carley-rae-jepsen', 'cher-lloyd',\n",
    "           'enrique-iglesias', 'ed-sheeran', 'chance-the-rapper', 'charli-xcx', 'demi-lovato',\n",
    "           'eileen-farrell', 'donny-marie-osmond', 'corbin-bleu', 'five-seconds-of-summer',\n",
    "           'grease', 'boy-meets-girl', 'cheetah-girls', 'dirty-dancing', 'britney-spears',\n",
    "           'bryce-vine', 'frank-ocean', 'ellie-goulding', 'christina-perri', 'ciara', 'eva',\n",
    "           'diana-ross','celine-dion', 'christopher-wilde', 'beatenberg', 'dua-lipa', 'adrianna-foster',\n",
    "           'bewitched', 'fifth-harmony', 'andy-grammer']\n",
    "namesList = [\"ariana-grande\"]\n",
    "\n",
    "fullLyrics = []\n",
    "with open(LYRICS_DIR) as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        currRow = []\n",
    "        index = row[0]\n",
    "        song = row[1]\n",
    "        year = row[2]\n",
    "        artist = row[3]\n",
    "        genre = row[4]\n",
    "        lyrics = row[5]\n",
    "        \n",
    "        if (genre == \"Pop\" and artist in namesList):\n",
    "            lyrics = replace(lyrics)\n",
    "            currRow.append(index)\n",
    "            currRow.append(song)\n",
    "            currRow.append(year)\n",
    "            currRow.append(artist)\n",
    "            currRow.append(genre)\n",
    "            currRow.append(lyrics)\n",
    "\n",
    "            fullLyrics.append(currRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETED_LYRICS_DIR = '/Users/jacobwagner/Desktop/lyricsCut.txt'\n",
    "\n",
    "file1 = open(COMPLETED_LYRICS_DIR, \"w+\")\n",
    "for row in fullLyrics:\n",
    "    currLyrics = row[5]\n",
    "    file1.write(currLyrics)\n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset's first 3 rap lines: \n",
      "['Oh baby, how you doing?', \"You know I'm gonna cut right to the chase\", 'Some women were made but me, myself']\n"
     ]
    }
   ],
   "source": [
    "target_url = '/Users/jacobwagner/Desktop/lyrics.txt'\n",
    "lyrics_file = open(target_url,\"r\")\n",
    "dirty_rap_source = lyrics_file.read()\n",
    "rap_source = [x.split(\"\\r\")[0] for x in dirty_rap_source.split(\"\\n\")]\n",
    "while \"\" in rap_source:\n",
    "  rap_source.remove(\"\")\n",
    "while \" \" in rap_source:\n",
    "  rap_source.remove(\" \")\n",
    "print (\"Your dataset's first 3 rap lines: \")\n",
    "print (rap_source[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install markovify\n",
    "!pip install pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import re\n",
    "import pronouncing\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just the parameters of the network.\n",
    "depth = 4  # depth of the network. changing will require a retrain\n",
    "maxsyllables = 30  # maximum syllables per line. Change this freely without retraining the network\n",
    "rap_length = 5 # number of lines in the rap song\n",
    "epochs_to_train = 3 # how many times the network trains on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(depth):\n",
    "    # Sequential() creates a linear stack of layers\n",
    "    model = Sequential()\n",
    "    # Adds a LSTM layer as the first layer in the network with\n",
    "    # 4 units (nodes), and a 2x2 tensor (which is the same shape as the\n",
    "    # training data)\n",
    "    model.add(LSTM(4, input_shape=(2, 2), return_sequences=True))\n",
    "    # adds 'depth' number of layers to the network with 8 nodes each\n",
    "    for i in range(depth):\n",
    "        model.add(LSTM(8, return_sequences=True))\n",
    "    # adds a final layer with 2 nodes for the output\n",
    "    model.add(LSTM(2, return_sequences=True))\n",
    "    # prints a summary representation of the model\n",
    "    model.summary()\n",
    "    # configures the learning process for the network / model\n",
    "    # the optimizer function rmsprop: optimizes the gradient descent\n",
    "    # the loss function: mse: will use the \"mean_squared_error when trying to improve\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='mse')\n",
    "\n",
    "    #if artist + \".rap\" in os.listdir(\".\") and train_mode == False:\n",
    "    #    # loads the weights from the hdf5 file saved earlier\n",
    "    #    model.load_weights(str(artist + \".rap\"))\n",
    "    #    print \"loading saved network: \" + str(artist) + \".rap\"\n",
    "    return model\n",
    "\n",
    "\n",
    "def markov(text_file):\n",
    "    read = rap_source\n",
    "    # markovify goes line by line of the lyrics.txt file and\n",
    "    # creates a model of the text which allows us to use\n",
    "    # make_sentence() later on to create a bar for lyrics\n",
    "    # creates a probability distribution for all the words\n",
    "    # so it can generate words based on the current word we're on\n",
    "    text_model = markovify.NewlineText(read)\n",
    "    return text_model\n",
    "\n",
    "\n",
    "# used when generating bars and making sure the length is not longer\n",
    "# than the max syllables, and will continue to generate bars until\n",
    "# the amount of syllables is less than the max syllables\n",
    "def syllables(line):\n",
    "    count = 0\n",
    "    for word in line.split(\" \"):\n",
    "        vowels = 'aeiouy'\n",
    "        word = word.lower().strip(\".:;?!\")\n",
    "        if len(word) > 0:\n",
    "          if word[0] in vowels:\n",
    "              count += 1\n",
    "          for index in range(1, len(word)):\n",
    "              if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                  count += 1\n",
    "          if word.endswith('e'):\n",
    "              count -= 1\n",
    "          if word.endswith('le'):\n",
    "              count += 1\n",
    "          if count == 0:\n",
    "              count += 1\n",
    "    return count / maxsyllables\n",
    "\n",
    "\n",
    "# writes a rhyme list to a rhymes file that allows for use when\n",
    "# building the dataset, and composing the rap\n",
    "def rhymeindex(lyrics):\n",
    "    #if str(artist) + \".rhymes\" in os.listdir(\".\") and train_mode == False:\n",
    "    #    print \"loading saved rhymes from \" + str(artist) + \".rhymes\"\n",
    "    #    return open(str(artist) + \".rhymes\", \"r\").read().split(\"\\n\")\n",
    "    if True:\n",
    "        rhyme_master_list = []\n",
    "        print(\"Alright, building the list of all the rhymes\")\n",
    "        for i in lyrics:\n",
    "            # grabs the last word in each bar\n",
    "            word = re.sub(r\"\\W+\", '', i.split(\" \")[-1]).lower()\n",
    "            # pronouncing.rhymes gives us a word that rhymes with the word being passed in\n",
    "            rhymeslist = pronouncing.rhymes(word)\n",
    "            # need to convert the unicode rhyme words to UTF8\n",
    "            rhymeslist = [x.encode('UTF8') for x in rhymeslist]\n",
    "            # rhymeslistends contains the last two characters for each word\n",
    "            # that could potentially rhyme with our word\n",
    "            rhymeslistends = []\n",
    "            for i in rhymeslist:\n",
    "                rhymeslistends.append(i[-2:])\n",
    "            try:\n",
    "                # rhymescheme gets all the unique two letter endings and then\n",
    "                # finds the one that occurs the most\n",
    "                rhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n",
    "            except Exception:\n",
    "                rhymescheme = word[-2:]\n",
    "            rhyme_master_list.append(rhymescheme)\n",
    "        # rhyme_master_list is a list of the two letters endings that appear\n",
    "        # the most in the rhyme list for the word\n",
    "        rhyme_master_list = list(set(rhyme_master_list))\n",
    "\n",
    "        reverselist = [x[::-1] for x in rhyme_master_list]\n",
    "        reverselist = sorted(reverselist)\n",
    "        # rhymelist is a list of the two letter endings (reversed)\n",
    "        # the reason the letters are reversed and sorted is so\n",
    "        # if the network messes up a little bit and doesn't return quite\n",
    "        # the right values, it can often lead to picking the rhyme ending next to the\n",
    "        # expected one in the list. But now the endings will be sorted and close together\n",
    "        # so if the network messes up, that's alright and as long as it's just close to the\n",
    "        # correct rhymes\n",
    "        rhymelist = [x[::-1] for x in reverselist]\n",
    "\n",
    "        #f = open(str(artist) + \".rhymes\", \"w\")\n",
    "        #f.write(\"\\n\".join(rhymelist))\n",
    "        #f.close()\n",
    "        print(rhymelist)\n",
    "        return rhymelist\n",
    "\n",
    "\n",
    "# converts the index of the most common rhyme ending\n",
    "# into a float\n",
    "def rhyme(line, rhyme_list):\n",
    "    word = re.sub(r\"\\W+\", '', line.split(\" \")[-1]).lower()\n",
    "    rhymeslist = pronouncing.rhymes(word)\n",
    "    rhymeslist = [x.encode('UTF8') for x in rhymeslist]\n",
    "    rhymeslistends = []\n",
    "    for i in rhymeslist:\n",
    "        rhymeslistends.append(i[-2:])\n",
    "    try:\n",
    "        rhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n",
    "    except Exception:\n",
    "        rhymescheme = word[-2:]\n",
    "    try:\n",
    "        float_rhyme = rhyme_list.index(rhymescheme)\n",
    "        float_rhyme = float_rhyme / float(len(rhyme_list))\n",
    "        return float_rhyme\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# grabs each line of the lyrics file and puts them\n",
    "# in their own index of a list, and then removes any empty lines\n",
    "# from the lyrics file and returns the list as bars\n",
    "def split_lyrics_file(text):\n",
    "    #text = open(text_file).read()\n",
    "    #text = text.split(\"\\n\")\n",
    "    while \"\" in text:\n",
    "        text.remove(\"\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# only ran when not training\n",
    "def generate_lyrics(lyrics_file):\n",
    "    bars = []\n",
    "    last_words = []\n",
    "    lyriclength = len(lyrics_file)\n",
    "    count = 0\n",
    "    markov_model = markov((\". \").join(lyrics_file) + \".\")\n",
    "\n",
    "    while len(bars) < lyriclength / 9 and count < lyriclength * 2:\n",
    "        # By default, the make_sentence method tries, a maximum of 10 times per invocation,\n",
    "        # to make a sentence that doesn't overlap too much with the original text.\n",
    "        # If it is successful, the method returns the sentence as a string.\n",
    "        # If not, it returns None. (https://github.com/jsvine/markovify)\n",
    "        bar = markov_model.make_sentence()\n",
    "\n",
    "        # make sure the bar isn't 'None' and that the amount of\n",
    "        # syllables is under the max syllables\n",
    "        if type(bar) != type(None) and syllables(bar) < 1:\n",
    "\n",
    "            # function to get the last word of the bar\n",
    "            def get_last_word(bar):\n",
    "                last_word = bar.split(\" \")[-1]\n",
    "                # if the last word is punctuation, get the word before it\n",
    "                if last_word[-1] in \"!.?,\":\n",
    "                    last_word = last_word[:-1]\n",
    "                return last_word\n",
    "\n",
    "            last_word = get_last_word(bar)\n",
    "            # only use the bar if it is unique and the last_word\n",
    "            # has only been seen less than 3 times\n",
    "            if bar not in bars and last_words.count(last_word) < 3:\n",
    "                bars.append(bar)\n",
    "                last_words.append(last_word)\n",
    "                count += 1\n",
    "\n",
    "    return bars\n",
    "\n",
    "\n",
    "# used to construct the 2x2 inputs for the LSTMs\n",
    "# the lyrics being passed in are lyrics (original lyrics if being trained,\n",
    "# or ours if it's already trained)\n",
    "def build_dataset(lyrics, rhyme_list):\n",
    "    dataset = []\n",
    "    line_list = []\n",
    "    # line_list becomes a list of the line from the lyrics, the syllables for that line (either 0 or 1 since\n",
    "    # syllables uses integer division by maxsyllables (16)), and then rhyme returns the most common word\n",
    "    # endings of the words that could rhyme with the last word of line\n",
    "    for line in lyrics:\n",
    "        line_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
    "        dataset.append(line_list)\n",
    "\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    # using range(len(dataset)) - 3 because of the way the indices are accessed to\n",
    "    # get the lines\n",
    "    for i in range(len(dataset) - 3):\n",
    "        line1 = dataset[i][1:]\n",
    "        line2 = dataset[i + 1][1:]\n",
    "        line3 = dataset[i + 2][1:]\n",
    "        line4 = dataset[i + 3][1:]\n",
    "\n",
    "        # populate the training data\n",
    "        # grabs the syllables and rhyme index here\n",
    "        x = [line1[0], line1[1], line2[0], line2[1]]\n",
    "        x = np.array(x)\n",
    "        # the data is shaped as a 2x2 array where each row is a\n",
    "        # [syllable, rhyme_index] pair\n",
    "        x = x.reshape(2, 2)\n",
    "        x_data.append(x)\n",
    "\n",
    "        # populate the target data\n",
    "        y = [line3[0], line3[1], line4[0], line4[1]]\n",
    "        y = np.array(y)\n",
    "        y = y.reshape(2, 2)\n",
    "        y_data.append(y)\n",
    "\n",
    "    # returns the 2x2 arrays as datasets\n",
    "    x_data = np.array(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    # print \"x shape \" + str(x_data.shape)\n",
    "    # print \"y shape \" + str(y_data.shape)\n",
    "    return x_data, y_data\n",
    "\n",
    "# only used when not training\n",
    "def compose_rap(lines, rhyme_list, lyrics_file, model):\n",
    "    rap_vectors = []\n",
    "    human_lyrics = split_lyrics_file(lyrics_file)\n",
    "\n",
    "    # choose a random line to start in from given lyrics\n",
    "    initial_index = random.choice(range(len(human_lyrics) - 1))\n",
    "    # create an initial_lines list consisting of 2 lines\n",
    "    initial_lines = human_lyrics[initial_index:initial_index + 8]\n",
    "\n",
    "    starting_input = []\n",
    "    for line in initial_lines:\n",
    "        # appends a [syllable, rhyme_index] pair to starting_input\n",
    "        starting_input.append([syllables(line), rhyme(line, rhyme_list)])\n",
    "\n",
    "    # predict generates output predictions for the given samples\n",
    "    # it's reshaped as a (1, 2, 2) so that the model can predict each\n",
    "    # 2x2 matrix of [syllable, rhyme_index] pairs\n",
    "    starting_vectors = model.predict(np.array([starting_input]).flatten().reshape(4, 2, 2))\n",
    "    rap_vectors.append(starting_vectors)\n",
    "\n",
    "    for i in range(rap_length):\n",
    "        rap_vectors.append(model.predict(np.array([rap_vectors[-1]]).flatten().reshape(4, 2, 2)))\n",
    "\n",
    "    return rap_vectors\n",
    "\n",
    "\n",
    "def vectors_into_song(vectors, generated_lyrics, rhyme_list):\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"About to write rap (this could take a moment)...\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # compare the last words to see if they are the same, if they are\n",
    "    # increment a penalty variable which grants penalty points for being\n",
    "    # uncreative\n",
    "    def last_word_compare(rap, line2):\n",
    "        penalty = 0\n",
    "        for line1 in rap:\n",
    "            word1 = line1.split(\" \")[-1]\n",
    "            word2 = line2.split(\" \")[-1]\n",
    "\n",
    "            # remove any punctuation from the words\n",
    "            while word1[-1] in \"?!,. \":\n",
    "                word1 = word1[:-1]\n",
    "\n",
    "            while word2[-1] in \"?!,. \":\n",
    "                word2 = word2[:-1]\n",
    "\n",
    "            if word1 == word2:\n",
    "                penalty += 0.2\n",
    "\n",
    "        return penalty\n",
    "\n",
    "    # vector_half is a single [syllable, rhyme_index] pair\n",
    "    # returns a score rating for a given line\n",
    "    def calculate_score(vector_half, syllables, rhyme, penalty):\n",
    "        desired_syllables = vector_half[0]\n",
    "        desired_rhyme = vector_half[1]\n",
    "        # desired_syllables is the number of syllables we want\n",
    "        desired_syllables = desired_syllables * maxsyllables\n",
    "        # desired rhyme is the index of the rhyme we want\n",
    "        desired_rhyme = desired_rhyme * len(rhyme_list)\n",
    "\n",
    "        # generate a score by subtracting from 1 the sum of the difference between\n",
    "        # predicted syllables and generated syllables and the difference between\n",
    "        # the predicted rhyme and generated rhyme and then subtract the penalty\n",
    "        score = 1.0 - (abs((float(desired_syllables) - float(syllables))) + abs(\n",
    "            (float(desired_rhyme) - float(rhyme)))) - penalty\n",
    "\n",
    "        return score\n",
    "\n",
    "    # generated a list of all the lines from generated_lyrics with their\n",
    "    # line, syllables, and rhyme float value\n",
    "    dataset = []\n",
    "    for line in generated_lyrics:\n",
    "        line_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
    "        dataset.append(line_list)\n",
    "\n",
    "    rap = []\n",
    "\n",
    "    vector_halves = []\n",
    "    for vector in vectors:\n",
    "        # vectors are the 2x2 rap_vectors (predicted bars) generated by compose_rap()\n",
    "        # separate every vector into a half (essentially one bar) where each\n",
    "        # has a pair of [syllables, rhyme_index]\n",
    "        vector_halves.append(list(vector[0][0]))\n",
    "        vector_halves.append(list(vector[0][1]))\n",
    "\n",
    "    for vector in vector_halves:\n",
    "        # Each vector (predicted bars) is scored against every generated bar ('item' below)\n",
    "        # to find the generated bar that best matches (highest score) the vector predicted\n",
    "        # by the model. This bar is then added to the final rap and also removed from the\n",
    "        # generated lyrics (dataset) so that we don't get duplicate lines in the final rap.\n",
    "        scorelist = []\n",
    "        for item in dataset:\n",
    "            # item is one of the generated bars from the Markov model\n",
    "            line = item[0]\n",
    "\n",
    "            if len(rap) != 0:\n",
    "                penalty = last_word_compare(rap, line)\n",
    "            else:\n",
    "                penalty = 0\n",
    "            # calculate the score of the current line\n",
    "            total_score = calculate_score(vector, item[1], item[2], penalty)\n",
    "            score_entry = [line, total_score]\n",
    "            # add the score of the current line to a scorelist\n",
    "            scorelist.append(score_entry)\n",
    "\n",
    "        fixed_score_list = []\n",
    "        for score in scorelist:\n",
    "            fixed_score_list.append(float(score[1]))\n",
    "        # get the line with the max valued score from the fixed_score_list\n",
    "        max_score = max(fixed_score_list)\n",
    "        for item in scorelist:\n",
    "            if item[1] == max_score:\n",
    "                # append item[0] (the line) to the rap\n",
    "                rap.append(item[0])\n",
    "                print(str(item[0]))\n",
    "\n",
    "                # remove the line we added to the rap so\n",
    "                # it doesn't get chosen again\n",
    "                for i in dataset:\n",
    "                    if item[0] == i[0]:\n",
    "                        dataset.remove(i)\n",
    "                        break\n",
    "                break\n",
    "    return rap\n",
    "\n",
    "\n",
    "def train(x_data, y_data, model):\n",
    "    # fit is used to train the model for 5 'epochs' (iterations) where\n",
    "    # the x_data is the training data, and the y_data is the target data\n",
    "    # x is the training and y is the target data\n",
    "    # batch_size is a subset of the training data (2 in this case)\n",
    "    # verbose simply shows a progress bar\n",
    "    model.fit(np.array(x_data), np.array(y_data),\n",
    "              batch_size=4,\n",
    "              epochs=epochs_to_train,\n",
    "              verbose=1)\n",
    "    # save_weights saves the best weights from training to a hdf5 file\n",
    "    #model.save_weights(artist + \".rap\")\n",
    "\n",
    "\n",
    "def main(depth):\n",
    "    train_mode = True\n",
    "    model = create_network(depth)\n",
    "    # change the lyrics file to the file with the lyrics you want to be trained on\n",
    "    \n",
    "    text_file = rap_source\n",
    "    \n",
    "    bars = split_lyrics_file(text_file)\n",
    "\n",
    "\n",
    "\n",
    "    rhyme_list = rhymeindex(bars)\n",
    "    \n",
    "    x_data, y_data = build_dataset(bars, rhyme_list)\n",
    "    train(x_data, y_data, model)\n",
    "    \n",
    "    bars = generate_lyrics(text_file)\n",
    "    \n",
    "    vectors = compose_rap(bars, rhyme_list, text_file, model)\n",
    "    rap = vectors_into_song(vectors, bars, rhyme_list)\n",
    "    \n",
    "    for bar in rap:\n",
    "        print (bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ef4581d929ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Run this to get the actual Rap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-cf4a05304ce7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(depth)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mtrain_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0;31m# change the lyrics file to the file with the lyrics you want to be trained on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cf4a05304ce7>\u001b[0m in \u001b[0;36mcreate_network\u001b[0;34m(depth)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Sequential() creates a linear stack of layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Adds a LSTM layer as the first layer in the network with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 4 units (nodes), and a 2x2 tensor (which is the same shape as the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "main(depth) #Run this to get the actual Rap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
